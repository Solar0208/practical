1.nltk Adding or Removing
# pip install nltk

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download('stopwords')
nltk.download('punkt')

text = "Yashesh likes to play football, however he is not too fond of tennis."
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]
print(tokens_without_sw)

all_stopwords = stopwords.words('english')
all_stopwords.append('play')
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]
print(tokens_without_sw)

all_stopwords.remove('not')
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]
print(tokens_without_sw)


2.Gensim Adding and Removing Stop Words
# pip install gensim nltk

import nltk
from nltk.tokenize import word_tokenize
import gensim
from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS

nltk.download('punkt')

text = "Yashesh likes to play football, however he is not too fond of tennis."
filtered_sentence = remove_stopwords(text)
print(filtered_sentence)

all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]
print(tokens_without_sw)

sw_list = {"not"}
all_stopwords_gensim = STOPWORDS.difference(sw_list)
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]
print(tokens_without_sw)

3. Spacy Adding and Removing Stop Words
# pip install spacy nltk
# python -m spacy download en_core_web_sm

import spacy
import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')

sp = spacy.load('en_core_web_sm')
all_stopwords = sp.Defaults.stop_words
all_stopwords.add("play")

text = "Yashesh likes to play football, however he is not too fond of tennis."
text_tokens = word_tokenize(text)
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]
print(tokens_without_sw)

all_stopwords.remove('not')
tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]
print(tokens_without_sw)
